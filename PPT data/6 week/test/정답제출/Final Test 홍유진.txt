#[1,2]#
1): [1,0,0,0
     0,1,0,0
     0,0,1,0]
2): 변폭이 너무 커질 수 있다(지수 이동평균을 써야함)
3):O
4):cpu는 한꺼번에 처리하지만 gpu는 나눠서 처리한다
5):
6):
7):
8):훈련셋,검증셋,테스트셋/학습속도가 빠르지만, 학습속도가 느리다/데이터셋
9:)
10:)
11:)
12:) 
13:) 여러개의 층으로 학습한다
14:)
15:) [ 1 4
       2 5
       3 6 ]
16:) 거짓
17:) 1,4
18:) 
#[3,4]#
1): 새로 생성된값보다 이전값에 비중을 두어 순간적인 변폭을 줄여 변화를 잘 관찰할 수 있게 해준다
2): 강화학습은 비지도학습과 다르게 랜덤적인 요소를 계속 시도한다
3): 무한대
4): len(sequences)
5): 네트워크의 병목을 막기 위해서
6): 네트워크 규제, 가중치 추가, 훈련 데이터 모으기, 드롭아웃 계층 추가
7): binary crossentropy
8): sequential 모델, 
9:) 네트워크의 병목을 막기 위해서
10:) softmax 함수
11:) mse
12:) 강화학습은 비지도학습과 다르게 랜덤적인 요소를 계속 시도한다.
13:) 5
14:) 4
15:) 24개
16:) (1) O (2) X (3) O
17:) 
18:) 데이터 정규화를 해준다.
19:) 1,4
20:) 빨간 선
#[5,6]#
1): 층을 축소시키는것, maxpooling
2): 288
3): 2
4): X
5): CNN,RNN
6): 3
7): 
8):데이터를 몇개 증식시킬것인지
9:) 
10:)
11:)
12:) 딕셔너리로 단어를 매핑하여 나중에 딕셔너리에서 찾아쓸수있게한다
13:)
15:)LSTM,GRU,RNN
16:)
17:) O
18:) O
#[7,8]#
1):
2): 5
3): 5
4): 낮은
5): 5
6): X
7): O
8): 에포크가 3씩 증가한다
9): O
10:) 하이퍼 파라미터는 사용자가 직접 설정하는 것이고 파라미터는 이미 정해져 있는 것이다
11:) 인코더와 디코더가 있고, 인코더가 입력값을 넣으면 디코더로 디코딩을하여 출력한다
12:) X
13:) 
14:) 과대적합,네트워크 규제
15:) 1,5
16:) nonparametric method
17:) 4
18:)
19:) 