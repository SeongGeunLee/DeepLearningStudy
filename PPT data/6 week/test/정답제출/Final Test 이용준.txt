#[1,2]#
1): [1.,0.,0.,0.]
    [0.,1.,0.,0.]
    [0.,0.,1.,0.]
2): 파라미터값이 전역 최솟값이 아닌 지역최솟값에 머물수있음
3): O
4): CPU는 순차적으로 처리하고 GPU는 병렬로 처리함
5): [19, 32] 
    [18, 25]
6): (1), 2
    (2), float
7): my_slice= train_images[ : , 14:-7 , 14:-7 ]
8): 토큰, 학습하는데 , 오래걸린다 , 배치
9): 지도학습, 강화학습, 비지도학습
10):x=np.transpos(x)
11): 지도학습, 강화학습, 비지도학습
12): 학습률을 적당하게 조절하거나, 손실함수를 변경한다.
13): 깊다
14): Cuda는 gpu를 사용해서 병렬로 처리가 가능하게 해주고
cuda c는 병렬로 처리할 수 있게 c처럼 만들어논 언어

15): [1,4]
     [2,5]
     [3,6]	
16): 거짓
17): 1,5
18): 학습
#[3,4]#
1):예측값과 정답값 차이의 제곱평균을 구한것

2): 하이퍼파라미터의 유무

3): NONE
4): sequences.len
5): 중간층의 개수가 적을경우 제데로 학습이 되지 않아서 정확도가 감소하는데
 중간층의 개수가 많으면 많을 수록 가중치가 최적의 값을 찾아가므로 정확도가
증가 하기때문
 
6):드롭아웃 계층 추가, 히든층추가, 학습률 조절, 가중치규제 추가
7): 카테고리컬 크로스엔트로피
8):
9): 중간층의 개수가 적을경우 제데로 학습이 되지 않아서 정확도가 감소하는데
 중간층의 개수가 많으면 많을 수록 가중치가 최적의 값을 찾아가므로 정확도가
증가 하기때문
10): softmax
11): relu
12): 하이퍼파라미터의 유무
13): 1번
14): 1번
15): 4개
16): (1) o
      (2) x
      (3) o
17): 
18): 데이터 정규화
19): 3,4,5
20): ROC 선
#[5,6]#
1):
2): 3*3*32
3): 4번
4): x
5): CNN, RNN
6): 3번
7): aactivation--> activation으로 수정한다.
8): 데이터를 증식시킬때 20개의 묶음씩 증식시킨다는의미
9): 2,4
10): 
11): 
12): 텍스트의 토큰을 담을수있음
13): 
14):
15): many to many, one to many , many to one
16): 
17): O
18): X
#[7,8]#
1): 
2):3번
3):1번
4):낮은
5): 5번
6): (1)X
    (2)X
7): 3번
8): 더이상 가중치가 향상되지 않을 때 3번학습 이후에 종료 
9): O
10): 사용자가 튜닝할수 있는지 없는지
11):
12): X
13): 
14): 과대적합, 깊이별 분리 합성곱
15): 1,5
16): parametric method
17): 1번
18): 
19): 입력