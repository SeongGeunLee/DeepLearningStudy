#[1,2]#
1):[1, 0, 0, 0]
   [0, 1, 0, 0]
   [0, 0, 1, 0]
2):지역 최솟값에서 못 빠져나올 수 있다
3):X
4):CPU: 직렬처리/ GPU: 병렬 처리
5):[[19, 32],
    [18, 25]]
6): 
7):my_slice = train_images[ : , 14 : -7, 14 : -7 ]
8):배치, 느리지만, 빠르다, 미니배치
9): 입력데이터 기대출력 성능측정방법 
10):transpose
11):
12):모멘텀 사용
13):층을 깊게 쌓는다
14):CUDA는 GPU연산을 위해 NVIDIA가 만든 것  CUDA C는 프로그램 언어
15):[[1,4],
    [2,5],
    [3,6]]
16):거짓
17):1, 4
18):

#[3,4]#
1):이전값들의 평균에 비중 두고 새로운 값엔 조금의 비중을 두어 순간의 변폭을 줄여서 그래프의 전체적인 변화를 중요하게 표현
2):강화학습은 랜덤적인 요소가 있다
3):무한대
4):len(sequences)
5):많은 범주를 분류할 때 중간층의 크기가 작으면 데이터 병목현상 발생
6):드롭아웃 추가, 가중치 규제 적용, 데이터를 더 모은다, 드롭아웃 계층 추가
7):binary-crossentropy
8): 
9):많은 범주를 분류할 때 중간층의 크기가 작으면 데이터 병목현상 발생 -> 방지하기위해
10):softmax
11):mse
12):강화학습은 랜덤적인 요소가 있다
13):5
14):5
15):4
16):O X X
17): 
18):정규화
19):4
20):빨간선

#[5,6]#
1):이미지의 크기를 줄인다/풀링연산
2):288
3): 
4):X
5):cnn, rnn
6):3
7):
8):20씩 묶어서 증식시킨다
9):5
10):(1) : 1D-ConvNet은 속도가 빠르고 계산 비용이 훨 싸다
    (2) : 순서를 알 수 없어서 정확X
11):input gate, output gate
12): 
13):더 적은 파라미터를 가져서
14):정확도 속도 크기
15):one-to-many, many-to-one, many-to-many
16):0 0 0   0 0 0     
     0 1 2   2 3 0
     0 4 5   5 6 0

     0 4 5   5 6 0
     0 7 8   8 9 0
     0 0 0   0 0 0
17):X
18):X
#[7,8]#
1):
2):3
3):5
4):낮은
5):3
6):X, X
7):5
8):
9):O
10):하이퍼파라미터는 사용자가 조절가능
11): 
12):X
13):
14):그래디언트 소실 
15):1,5
16):Parametric method
17):2
18):
19):생성자는 판별자로부터 
     판별자는 정답으로부터

